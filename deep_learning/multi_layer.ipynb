{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Généralisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![w&b](multi_layer_png2/w&b.png \"w&b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialisation(dimensions):\n",
    "    parametres = {} # On initialise un dictionnaire vide\n",
    "    C = len(dimensions) # On récupère la len du tableau dimensions, car nous voulons accèder aux index\n",
    "\n",
    "    for c in range(1, C): # On commence à 1 la boucle car la première entrée sont les entrés X et on arréte à C pour ne pas prendre le neuronne final (car python arrete à -1).\n",
    "        parametres['W' + str(c)] = np.random.randn(dimensions[c], dimensions[c - 1]) # Nouvelle clée, accès aux valeur de dimensions, création de la matrice.\n",
    "        parametres['b' + str(c)] = np.random.randn(dimensions[c], 1)\n",
    "    return parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 (32, 2)\n",
      "b1 (32, 1)\n",
      "W2 (32, 32)\n",
      "b2 (32, 1)\n",
      "W3 (1, 32)\n",
      "b3 (1, 1)\n"
     ]
    }
   ],
   "source": [
    "parametres = initialisation([2, 32, 32, 1]) # [entrés X, couche 1, couche 2, …, couche n]\n",
    "\n",
    "for key, val in parametres.items():\n",
    "    print(key, val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![z&c](multi_layer_png2/z&c.png \"z&c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parametres):\n",
    "    C = len(parametres) // 2 # On divise avec 2 '/' pour retourner un nombre entier. Divise par deux pour obtenir le nombre de couche car il y a W et b dans la longueure.\n",
    "    activations = {'A0' : X} # Car la première couche ce calcul avec les X, pas avec n-1.\n",
    "\n",
    "    for c in range(1, C + 1): # Python s’arrete 1 nombre avant la fin de la boucle, donc C + 1 pour s’arréter à C\n",
    "        Z = parametres['W' + str(c)] @ activations['A' + str(c - 1)] + parametres['b' + str(c)]\n",
    "        activations['A' + str(c)] = 1 / (1 + np.exp(-Z)) # On append directement dans la boucel les A\n",
    "\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m activations \u001b[38;5;241m=\u001b[39m forward_propagation(X, parametres)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m activations\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "activations = forward_propagation(X, parametres)\n",
    "print(X.shape)\n",
    "for key, val in activations.items():\n",
    "    print(key, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(X, y, parametres, activations):\n",
    "    A1 = activations['A1']\n",
    "    A2 = activations['A2']\n",
    "    W2 = parametres['W2']\n",
    "\n",
    "    m = y.shape[1]\n",
    "\n",
    "    dZ2 = A2 - y\n",
    "    dW2 = 1 / m * dZ2 @ A1.T\n",
    "    db2 = 1 / m * np.sum(dZ2, axis=1, keepdims=True) # On met le parametre keepdims true pour garder les dimensions, car avec le broadcasting que nous executerons, cela peut casser les dims de la matrice.   \n",
    "\n",
    "    dZ1 = np.dot(W2.T, dZ2) * A1 * (1 - A1)\n",
    "    dW1 = 1 / m * dZ1 @ X.T\n",
    "    db1 = 1 / m * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    gradients = {\n",
    "        'dW1' : dW1,\n",
    "        'db1' : db1,\n",
    "        'dW2' : dW2,\n",
    "        'db2' : db2\n",
    "    }\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![back_propagation](multi_layer_png2/back_propagation.png \"back_propagation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(y, activations, parametres):\n",
    "    m = y.shape[1]\n",
    "    C = len(parametres) // 2\n",
    "    \n",
    "    dZ = activations['A' + str(C)] - y\n",
    "    gradients = {}\n",
    "\n",
    "    for c in reversed(range(1, C + 1)): \n",
    "        gradients['dW' + str(c)] = 1 / m * dZ @ activations['A' + str(c - 1)].T\n",
    "        gradients['db' + str(c)] = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "        if c > 1:\n",
    "            dZ = np.dot(parametres['W' + str(c)].T, dZ) * activations['A' + str(c - 1)] * (1 - activations['A' + str(c - 1)])\n",
    "\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW3 (1, 32)\n",
      "db3 (1, 1)\n",
      "dW2 (32, 32)\n",
      "db2 (32, 1)\n",
      "dW1 (32, 2)\n",
      "db1 (32, 1)\n"
     ]
    }
   ],
   "source": [
    "gradients = back_propagation(y, activations, parametres)\n",
    "\n",
    "for key, val in gradients.items():\n",
    "    print(key, val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![update](multi_layer_png2/update.png \"update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(parametres, gradients ,learning_rate): \n",
    "    C = len(parametres) // 2\n",
    "\n",
    "    for c in range(1, C + 1):\n",
    "        parametres['W' + str(c)] = parametres['W' + str(c)] - learning_rate * gradients['dW' + str(c)]\n",
    "        parametres['b' + str(c)] = parametres['b' + str(c)] - learning_rate * gradients['db' + str(c)]\n",
    "\n",
    "    return parametres"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
